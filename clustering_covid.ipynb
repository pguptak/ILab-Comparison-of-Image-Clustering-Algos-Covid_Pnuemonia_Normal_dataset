{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GIkw7A9qXctB",
    "outputId": "2374fc24-4493-4acb-c114-61d87897050e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn-extra\n",
      "  Downloading scikit-learn-extra-0.3.0.tar.gz (818 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/819.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m809.0/819.0 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from scikit-learn-extra) (2.0.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from scikit-learn-extra) (1.16.3)\n",
      "Requirement already satisfied: scikit-learn>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn-extra) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.23.0->scikit-learn-extra) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.23.0->scikit-learn-extra) (3.6.0)\n",
      "Building wheels for collected packages: scikit-learn-extra\n",
      "  Building wheel for scikit-learn-extra (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for scikit-learn-extra: filename=scikit_learn_extra-0.3.0-cp312-cp312-linux_x86_64.whl size=1959513 sha256=2e4288262ef8cd482d19ef5d8df0f9f7b4f7b5ced895c702e6b027cd7aa45753\n",
      "  Stored in directory: /root/.cache/pip/wheels/17/4d/c3/c6d5d563c1bf8146d059d63be3678abc2f2801fba0aaf5f0b8\n",
      "Successfully built scikit-learn-extra\n",
      "Installing collected packages: scikit-learn-extra\n",
      "Successfully installed scikit-learn-extra-0.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn-extra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rt5lWnO0XeDd",
    "outputId": "854c76c9-ae24-4e96-dbc4-9921c445f2de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hdbscan in /usr/local/lib/python3.12/dist-packages (0.8.41)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.12/dist-packages (from hdbscan) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.12/dist-packages (from hdbscan) (1.16.3)\n",
      "Requirement already satisfied: scikit-learn>=1.6 in /usr/local/lib/python3.12/dist-packages (from hdbscan) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from hdbscan) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6->hdbscan) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install hdbscan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8uAYQ1d3Xkx8",
    "outputId": "6a0f6d3d-dcda-47c1-a0c4-d6c426d60da7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-fuzzy\n",
      "  Downloading scikit_fuzzy-0.5.0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading scikit_fuzzy-0.5.0-py2.py3-none-any.whl (920 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/920.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m890.9/920.8 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m920.8/920.8 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scikit-fuzzy\n",
      "Successfully installed scikit-fuzzy-0.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-fuzzy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oQUD0D__YB4G",
    "outputId": "c4dde993-b3be-4a14-bca7-f6955cfc8ada"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 2.0.2\n",
      "Uninstalling numpy-2.0.2:\n",
      "  Successfully uninstalled numpy-2.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "tScEaGh8Yfgy",
    "outputId": "3c5f0bbf-a9e1-4970-e647-8875ebde7b0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.13.0.90 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-python-headless 4.13.0.90 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-contrib-python 4.13.0.90 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
      "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "1153deaf81734c9099e43d80437e15a6",
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install \"numpy<2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NHZNaaWRW2Pe",
    "outputId": "fdb5d2f6-1e5e-46f3-c4bd-f2b6117d2442"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/hdbscan/robust_single_linkage_.py:175: SyntaxWarning: invalid escape sequence '\\{'\n",
      "  $max \\{ core_k(a), core_k(b), 1/\\alpha d(a,b) \\}$.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import (\n",
    "    KMeans,\n",
    "    MiniBatchKMeans,\n",
    "    AgglomerativeClustering,\n",
    "    SpectralClustering,\n",
    "    MeanShift,\n",
    "    AffinityPropagation,\n",
    "    DBSCAN,\n",
    "    OPTICS,\n",
    "    Birch,\n",
    "    BisectingKMeans\n",
    ")\n",
    "\n",
    "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "import hdbscan\n",
    "import skfuzzy as fuzz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pOIpe3lSXBuX"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "original_df = pd.read_csv(\"original_labels.csv\")\n",
    "\n",
    "image_names = original_df[\"image_name\"].values\n",
    "original_labels = original_df[\"label\"].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "original_labels_enc = le.fit_transform(original_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yYf9dgYMXv20"
   },
   "outputs": [],
   "source": [
    "def compute_label_change(original, clustered):\n",
    "    return (np.sum(original != clustered) / len(original)) * 100\n",
    "\n",
    "\n",
    "def save_cluster_labels_csv(model, algo, image_names, original_labels, labels):\n",
    "    os.makedirs(\"clustering_labels\", exist_ok=True)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"image_name\": image_names,\n",
    "        \"original_label\": original_labels,   # ← human-readable\n",
    "        \"cluster_label\": labels               # ← cluster assignment\n",
    "    })\n",
    "\n",
    "    filename = f\"clustering_labels/{model}_{algo}.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ih_RpqIXx6Z"
   },
   "outputs": [],
   "source": [
    "def get_algorithms(X):\n",
    "    \"\"\"\n",
    "    Returns clustering algorithms that do NOT require training images.\n",
    "    \"\"\"\n",
    "\n",
    "    X_norm = normalize(X)\n",
    "\n",
    "    return {\n",
    "\n",
    "        # # ================= PARTITION-BASED =================\n",
    "        \"KMeans\": KMeans(n_clusters=NUM_CLASSES, random_state=42),\n",
    "\n",
    "        \"MiniBatchKMeans\": MiniBatchKMeans(\n",
    "            n_clusters=NUM_CLASSES, random_state=42\n",
    "        ),\n",
    "\n",
    "        \"KMedoids_PAM\": KMedoids(\n",
    "            n_clusters=NUM_CLASSES, method=\"pam\", random_state=42\n",
    "        ),\n",
    "\n",
    "        \"BisectingKMeans\": BisectingKMeans(\n",
    "            n_clusters=NUM_CLASSES, random_state=42\n",
    "        ),\n",
    "\n",
    "        # Spherical K-Means (handled as callable)\n",
    "        \"SphericalKMeans\": lambda X: KMeans(\n",
    "            n_clusters=NUM_CLASSES,\n",
    "            random_state=42\n",
    "        ).fit_predict(X_norm),\n",
    "\n",
    "        # Fuzzy C-Means (callable)\n",
    "        \"FuzzyCMeans\": lambda X: np.argmax(\n",
    "            fuzz.cluster.cmeans(\n",
    "                X_norm.T,\n",
    "                c=NUM_CLASSES,\n",
    "                m=2.0,\n",
    "                error=0.005,\n",
    "                maxiter=1000\n",
    "            )[1],\n",
    "            axis=0\n",
    "        ),\n",
    "\n",
    "        # ================= HIERARCHICAL =================\n",
    "        \"Agglomerative_Single\": AgglomerativeClustering(\n",
    "            n_clusters=NUM_CLASSES, linkage=\"single\"\n",
    "        ),\n",
    "\n",
    "        \"Agglomerative_Complete\": AgglomerativeClustering(\n",
    "            n_clusters=NUM_CLASSES, linkage=\"complete\"\n",
    "        ),\n",
    "\n",
    "        \"Agglomerative_Average\": AgglomerativeClustering(\n",
    "            n_clusters=NUM_CLASSES, linkage=\"average\"\n",
    "        ),\n",
    "\n",
    "        \"Agglomerative_Ward\": AgglomerativeClustering(\n",
    "            n_clusters=NUM_CLASSES, linkage=\"ward\"\n",
    "        ),\n",
    "\n",
    "        # ================= DENSITY-BASED =================\n",
    "        \"DBSCAN\": DBSCAN(eps=0.5, min_samples=5),\n",
    "\n",
    "        \"OPTICS\": OPTICS(min_samples=5),\n",
    "\n",
    "        \"HDBSCAN\": hdbscan.HDBSCAN(min_cluster_size=10),\n",
    "\n",
    "        \"MeanShift\": MeanShift(),\n",
    "\n",
    "        # ================= MODEL-BASED =================\n",
    "        \"GMM\": GaussianMixture(\n",
    "            n_components=NUM_CLASSES,\n",
    "            reg_covar=1e-4,\n",
    "            random_state=42\n",
    "        ),\n",
    "\n",
    "        \"BayesianGMM\": BayesianGaussianMixture(\n",
    "            n_components=NUM_CLASSES,\n",
    "            random_state=42\n",
    "        ),\n",
    "\n",
    "        # # ================= GRAPH-BASED =================\n",
    "        # \"SpectralClustering\": SpectralClustering(\n",
    "        #     n_clusters=NUM_CLASSES,\n",
    "        #     assign_labels=\"kmeans\",\n",
    "        #     random_state=42\n",
    "        # ),\n",
    "\n",
    "        # ================= LARGE-SCALE =================\n",
    "        \"BIRCH\": Birch(n_clusters=NUM_CLASSES),\n",
    "\n",
    "        # ================= MESSAGE PASSING =================\n",
    "        \"AffinityPropagation\": AffinityPropagation()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1q9-cIeaX1PD",
    "outputId": "9ffb1f2a-f808-4a17-8920-afc73632758e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing EfficientNetB0 =====\n",
      "→ Implementing KMeans ...\n",
      "   ✓ Done | Label change: 92.67%\n",
      "→ Implementing MiniBatchKMeans ...\n",
      "   ✓ Done | Label change: 48.78%\n",
      "→ Implementing KMedoids_PAM ...\n",
      "   ✓ Done | Label change: 63.41%\n",
      "→ Implementing BisectingKMeans ...\n",
      "   ✓ Done | Label change: 44.03%\n",
      "→ Implementing SphericalKMeans ...\n",
      "   ✓ Done | Label change: 94.11%\n",
      "→ Implementing FuzzyCMeans ...\n",
      "   ✓ Done | Label change: 42.79%\n",
      "→ Implementing Agglomerative_Single ...\n",
      "   ✓ Done | Label change: 68.94%\n",
      "→ Implementing Agglomerative_Complete ...\n",
      "   ✓ Done | Label change: 66.83%\n",
      "→ Implementing Agglomerative_Average ...\n",
      "   ✓ Done | Label change: 66.35%\n",
      "→ Implementing Agglomerative_Ward ...\n",
      "   ✓ Done | Label change: 89.65%\n",
      "→ Implementing DBSCAN ...\n",
      "   ✓ Done | Label change: 54.95%\n",
      "→ Implementing OPTICS ...\n",
      "   ✓ Done | Label change: 99.90%\n",
      "→ Implementing HDBSCAN ...\n",
      "   ✓ Done | Label change: 87.62%\n",
      "→ Implementing MeanShift ...\n",
      "   ✓ Done | Label change: 92.67%\n",
      "→ Implementing GMM ...\n",
      "   ✓ Done | Label change: 93.36%\n",
      "→ Implementing BayesianGMM ...\n",
      "   ✓ Done | Label change: 93.34%\n",
      "→ Implementing SpectralClustering ...\n",
      "   ✓ Done | Label change: 42.90%\n",
      "→ Implementing BIRCH ...\n",
      "   ✓ Done | Label change: 43.78%\n",
      "→ Implementing AffinityPropagation ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/cluster/_affinity_propagation.py:140: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Done | Label change: 99.98%\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 3\n",
    "MODEL_NAME = \"EfficientNetB0\"\n",
    "\n",
    "print(f\"\\n===== Processing {MODEL_NAME} =====\")\n",
    "\n",
    "X = np.load(f\"{MODEL_NAME}_features.npy\").astype(np.float64)\n",
    "\n",
    "algorithms = get_algorithms(X)\n",
    "results = []\n",
    "\n",
    "for algo_name, algo in algorithms.items():\n",
    "    print(f\"→ Implementing {algo_name} ...\")\n",
    "\n",
    "    try:\n",
    "        # Case 1: callable algorithms (Fuzzy, Spherical)\n",
    "        if callable(algo):\n",
    "            labels = algo(X)\n",
    "\n",
    "        # Case 2: GMM / BayesianGMM\n",
    "        elif hasattr(algo, \"predict\") and not hasattr(algo, \"fit_predict\"):\n",
    "            algo.fit(X)\n",
    "            labels = algo.predict(X)\n",
    "\n",
    "        # Case 3: sklearn clustering\n",
    "        else:\n",
    "            labels = algo.fit_predict(X)\n",
    "\n",
    "        # Skip degenerate clustering\n",
    "        if len(np.unique(labels)) < 2:\n",
    "            raise ValueError(\"Only one cluster formed\")\n",
    "\n",
    "        save_cluster_labels_csv(\n",
    "            MODEL_NAME,\n",
    "            algo_name,\n",
    "            image_names,\n",
    "            original_labels,\n",
    "            labels\n",
    "        )\n",
    "\n",
    "        change = compute_label_change(original_labels_enc, labels)\n",
    "        results.append([MODEL_NAME, algo_name, change])\n",
    "\n",
    "        print(f\"   ✓ Done | Label change: {change:.2f}%\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ✗ Failed: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\"model\", \"clustering\", \"label_percentage_change\"]\n",
    ").to_csv(\n",
    "    \"clustering_results.csv\",\n",
    "    mode=\"a\",\n",
    "    header=not os.path.exists(\"clustering_results.csv\"),\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q68O69lGaYTL",
    "outputId": "4acde283-3f43-464d-d251-a40a6bccc91c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing ResNet152 =====\n",
      "→ Implementing KMeans ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing MiniBatchKMeans ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing KMedoids_PAM ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:1389: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing BisectingKMeans ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing SphericalKMeans ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing FuzzyCMeans ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing Agglomerative_Single ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:1389: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Done | Label change: 68.88%\n",
      "→ Implementing Agglomerative_Complete ...\n",
      "   ✓ Done | Label change: 68.88%\n",
      "→ Implementing Agglomerative_Average ...\n",
      "   ✓ Done | Label change: 68.88%\n",
      "→ Implementing Agglomerative_Ward ...\n",
      "   ✓ Done | Label change: 68.88%\n",
      "→ Implementing DBSCAN ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing OPTICS ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing HDBSCAN ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing MeanShift ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing GMM ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:1389: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing BayesianGMM ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:1389: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing SpectralClustering ...\n",
      "   ✓ Done | Label change: 69.24%\n",
      "→ Implementing BIRCH ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing AffinityPropagation ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/cluster/_birch.py:727: ConvergenceWarning: Number of subclusters found (1) by BIRCH is less than (3). Decrease the threshold.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✗ Failed: Only one cluster formed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/cluster/_affinity_propagation.py:50: UserWarning: All samples have mutually equal similarities. Returning arbitrary cluster center(s).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 3\n",
    "MODEL_NAME = \"ResNet152\"\n",
    "\n",
    "print(f\"\\n===== Processing {MODEL_NAME} =====\")\n",
    "\n",
    "X = np.load(f\"{MODEL_NAME}_features.npy\").astype(np.float64)\n",
    "\n",
    "algorithms = get_algorithms(X)\n",
    "results = []\n",
    "\n",
    "for algo_name, algo in algorithms.items():\n",
    "    print(f\"→ Implementing {algo_name} ...\")\n",
    "\n",
    "    try:\n",
    "        # Case 1: callable algorithms (Fuzzy, Spherical)\n",
    "        if callable(algo):\n",
    "            labels = algo(X)\n",
    "\n",
    "        # Case 2: GMM / BayesianGMM\n",
    "        elif hasattr(algo, \"predict\") and not hasattr(algo, \"fit_predict\"):\n",
    "            algo.fit(X)\n",
    "            labels = algo.predict(X)\n",
    "\n",
    "        # Case 3: sklearn clustering\n",
    "        else:\n",
    "            labels = algo.fit_predict(X)\n",
    "\n",
    "        # Skip degenerate clustering\n",
    "        if len(np.unique(labels)) < 2:\n",
    "            raise ValueError(\"Only one cluster formed\")\n",
    "\n",
    "        save_cluster_labels_csv(\n",
    "            MODEL_NAME,\n",
    "            algo_name,\n",
    "            image_names,\n",
    "            original_labels,\n",
    "            labels\n",
    "        )\n",
    "\n",
    "        change = compute_label_change(original_labels_enc, labels)\n",
    "        results.append([MODEL_NAME, algo_name, change])\n",
    "\n",
    "        print(f\"   ✓ Done | Label change: {change:.2f}%\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ✗ Failed: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\"model\", \"clustering\", \"label_percentage_change\"]\n",
    ").to_csv(\n",
    "    \"clustering_results.csv\",\n",
    "    mode=\"a\",\n",
    "    header=not os.path.exists(\"clustering_results.csv\"),\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZYIzjssY0oK",
    "outputId": "b7e14b8f-05d1-4c39-cc24-aaa171e4b676"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing MobileNetV3 =====\n",
      "→ Implementing KMeans ...\n",
      "   ✓ Done | Label change: 57.69%\n",
      "→ Implementing MiniBatchKMeans ...\n",
      "   ✓ Done | Label change: 77.18%\n",
      "→ Implementing KMedoids_PAM ...\n",
      "   ✓ Done | Label change: 66.76%\n",
      "→ Implementing BisectingKMeans ...\n",
      "   ✓ Done | Label change: 59.10%\n",
      "→ Implementing SphericalKMeans ...\n",
      "   ✓ Done | Label change: 66.07%\n",
      "→ Implementing FuzzyCMeans ...\n",
      "   ✓ Done | Label change: 57.44%\n",
      "→ Implementing Agglomerative_Single ...\n",
      "   ✓ Done | Label change: 68.96%\n",
      "→ Implementing Agglomerative_Complete ...\n",
      "   ✓ Done | Label change: 58.09%\n",
      "→ Implementing Agglomerative_Average ...\n",
      "   ✓ Done | Label change: 68.75%\n",
      "→ Implementing Agglomerative_Ward ...\n",
      "   ✓ Done | Label change: 69.99%\n",
      "→ Implementing DBSCAN ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing OPTICS ...\n",
      "   ✓ Done | Label change: 99.85%\n",
      "→ Implementing HDBSCAN ...\n",
      "   ✓ Done | Label change: 69.38%\n",
      "→ Implementing MeanShift ...\n",
      "   ✓ Done | Label change: 70.16%\n",
      "→ Implementing GMM ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing BayesianGMM ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Done | Label change: 69.45%\n",
      "→ Implementing SpectralClustering ...\n",
      "   ✓ Done | Label change: 58.05%\n",
      "→ Implementing BIRCH ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing AffinityPropagation ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/cluster/_birch.py:727: ConvergenceWarning: Number of subclusters found (1) by BIRCH is less than (3). Decrease the threshold.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/cluster/_affinity_propagation.py:140: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Done | Label change: 99.98%\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 3\n",
    "MODEL_NAME = \"MobileNetV3\"\n",
    "\n",
    "print(f\"\\n===== Processing {MODEL_NAME} =====\")\n",
    "\n",
    "X = np.load(f\"{MODEL_NAME}_features.npy\").astype(np.float64)\n",
    "\n",
    "algorithms = get_algorithms(X)\n",
    "results = []\n",
    "\n",
    "for algo_name, algo in algorithms.items():\n",
    "    print(f\"→ Implementing {algo_name} ...\")\n",
    "\n",
    "    try:\n",
    "        # Case 1: callable algorithms (Fuzzy, Spherical)\n",
    "        if callable(algo):\n",
    "            labels = algo(X)\n",
    "\n",
    "        # Case 2: GMM / BayesianGMM\n",
    "        elif hasattr(algo, \"predict\") and not hasattr(algo, \"fit_predict\"):\n",
    "            algo.fit(X)\n",
    "            labels = algo.predict(X)\n",
    "\n",
    "        # Case 3: sklearn clustering\n",
    "        else:\n",
    "            labels = algo.fit_predict(X)\n",
    "\n",
    "        # Skip degenerate clustering\n",
    "        if len(np.unique(labels)) < 2:\n",
    "            raise ValueError(\"Only one cluster formed\")\n",
    "\n",
    "        save_cluster_labels_csv(\n",
    "            MODEL_NAME,\n",
    "            algo_name,\n",
    "            image_names,\n",
    "            original_labels,\n",
    "            labels\n",
    "        )\n",
    "\n",
    "        change = compute_label_change(original_labels_enc, labels)\n",
    "        results.append([MODEL_NAME, algo_name, change])\n",
    "\n",
    "        print(f\"   ✓ Done | Label change: {change:.2f}%\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ✗ Failed: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\"model\", \"clustering\", \"label_percentage_change\"]\n",
    ").to_csv(\n",
    "    \"clustering_results.csv\",\n",
    "    mode=\"a\",\n",
    "    header=not os.path.exists(\"clustering_results.csv\"),\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BKmv704abUOL",
    "outputId": "851218f0-d4f1-47af-df85-3e8d1e60991f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing VGG19 =====\n",
      "→ Implementing KMeans ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing MiniBatchKMeans ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing KMedoids_PAM ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:1389: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing BisectingKMeans ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing SphericalKMeans ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing FuzzyCMeans ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing Agglomerative_Single ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:1389: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Done | Label change: 68.88%\n",
      "→ Implementing Agglomerative_Complete ...\n",
      "   ✓ Done | Label change: 68.88%\n",
      "→ Implementing Agglomerative_Average ...\n",
      "   ✓ Done | Label change: 68.88%\n",
      "→ Implementing Agglomerative_Ward ...\n",
      "   ✓ Done | Label change: 68.88%\n",
      "→ Implementing DBSCAN ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing OPTICS ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing HDBSCAN ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing MeanShift ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing GMM ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:1389: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing BayesianGMM ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:1389: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing SpectralClustering ...\n",
      "   ✓ Done | Label change: 69.24%\n",
      "→ Implementing BIRCH ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing AffinityPropagation ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/cluster/_birch.py:727: ConvergenceWarning: Number of subclusters found (1) by BIRCH is less than (3). Decrease the threshold.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✗ Failed: Only one cluster formed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/cluster/_affinity_propagation.py:50: UserWarning: All samples have mutually equal similarities. Returning arbitrary cluster center(s).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 3\n",
    "MODEL_NAME = \"VGG19\"\n",
    "\n",
    "print(f\"\\n===== Processing {MODEL_NAME} =====\")\n",
    "\n",
    "X = np.load(f\"{MODEL_NAME}_features.npy\").astype(np.float64)\n",
    "\n",
    "algorithms = get_algorithms(X)\n",
    "results = []\n",
    "\n",
    "for algo_name, algo in algorithms.items():\n",
    "    print(f\"→ Implementing {algo_name} ...\")\n",
    "\n",
    "    try:\n",
    "        # Case 1: callable algorithms (Fuzzy, Spherical)\n",
    "        if callable(algo):\n",
    "            labels = algo(X)\n",
    "\n",
    "        # Case 2: GMM / BayesianGMM\n",
    "        elif hasattr(algo, \"predict\") and not hasattr(algo, \"fit_predict\"):\n",
    "            algo.fit(X)\n",
    "            labels = algo.predict(X)\n",
    "\n",
    "        # Case 3: sklearn clustering\n",
    "        else:\n",
    "            labels = algo.fit_predict(X)\n",
    "\n",
    "        # Skip degenerate clustering\n",
    "        if len(np.unique(labels)) < 2:\n",
    "            raise ValueError(\"Only one cluster formed\")\n",
    "\n",
    "        save_cluster_labels_csv(\n",
    "            MODEL_NAME,\n",
    "            algo_name,\n",
    "            image_names,\n",
    "            original_labels,\n",
    "            labels\n",
    "        )\n",
    "\n",
    "        change = compute_label_change(original_labels_enc, labels)\n",
    "        results.append([MODEL_NAME, algo_name, change])\n",
    "\n",
    "        print(f\"   ✓ Done | Label change: {change:.2f}%\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ✗ Failed: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\"model\", \"clustering\", \"label_percentage_change\"]\n",
    ").to_csv(\n",
    "    \"clustering_results.csv\",\n",
    "    mode=\"a\",\n",
    "    header=not os.path.exists(\"clustering_results.csv\"),\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-y4rgMtjcQD0",
    "outputId": "f75698f6-31be-4f6f-87ac-12012358b826"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing Xception =====\n",
      "→ Implementing KMeans ...\n",
      "   ✓ Done | Label change: 84.58%\n",
      "→ Implementing MiniBatchKMeans ...\n",
      "   ✓ Done | Label change: 65.63%\n",
      "→ Implementing KMedoids_PAM ...\n",
      "   ✓ Done | Label change: 48.39%\n",
      "→ Implementing BisectingKMeans ...\n",
      "   ✓ Done | Label change: 49.23%\n",
      "→ Implementing SphericalKMeans ...\n",
      "   ✓ Done | Label change: 85.62%\n",
      "→ Implementing FuzzyCMeans ...\n",
      "   ✓ Done | Label change: 81.37%\n",
      "→ Implementing Agglomerative_Single ...\n",
      "   ✓ Done | Label change: 68.92%\n",
      "→ Implementing Agglomerative_Complete ...\n",
      "   ✓ Done | Label change: 65.09%\n",
      "→ Implementing Agglomerative_Average ...\n",
      "   ✓ Done | Label change: 65.19%\n",
      "→ Implementing Agglomerative_Ward ...\n",
      "   ✓ Done | Label change: 46.46%\n",
      "→ Implementing DBSCAN ...\n",
      "   ✓ Done | Label change: 87.26%\n",
      "→ Implementing OPTICS ...\n",
      "   ✓ Done | Label change: 99.85%\n",
      "→ Implementing HDBSCAN ...\n",
      "   ✓ Done | Label change: 70.12%\n",
      "→ Implementing MeanShift ...\n",
      "   ✓ Done | Label change: 70.66%\n",
      "→ Implementing GMM ...\n",
      "   ✓ Done | Label change: 86.29%\n",
      "→ Implementing BayesianGMM ...\n",
      "   ✓ Done | Label change: 86.94%\n",
      "→ Implementing SpectralClustering ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/manifold/_spectral_embedding.py:329: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2287180743.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Case 3: sklearn clustering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Skip degenerate clustering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/cluster/_spectral.py\u001b[0m in \u001b[0;36mfit_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mCluster\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m         \"\"\"\n\u001b[0;32m--> 793\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__sklearn_tags__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_predict\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;31m# non-optimized default implementation; override when a better\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;31m# method is possible for a given clustering algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/cluster/_spectral.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;31m# and should be kept for spectral clustering (drop_first = False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;31m# See spectral_embedding documentation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m         maps = _spectral_embedding(\n\u001b[0m\u001b[1;32m    746\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffinity_matrix_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/manifold/_spectral_embedding.py\u001b[0m in \u001b[0;36m_spectral_embedding\u001b[0;34m(adjacency, n_components, eigen_solver, random_state, eigen_tol, norm_laplacian, drop_first)\u001b[0m\n\u001b[1;32m    370\u001b[0m                 \u001b[0mlaplacian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 372\u001b[0;31m             _, diffusion_map = eigsh(\n\u001b[0m\u001b[1;32m    373\u001b[0m                 \u001b[0mlaplacian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"LM\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py\u001b[0m in \u001b[0;36meigsh\u001b[0;34m(A, k, M, sigma, which, v0, ncv, maxiter, tol, return_eigenvectors, Minv, OPinv, mode)\u001b[0m\n\u001b[1;32m   1702\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_ARPACK_LOCK\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverged\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1704\u001b[0;31m             \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_eigenvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py\u001b[0m in \u001b[0;36miterate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    547\u001b[0m                                 self.ipntr, self.workd, self.workl, self.info)\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mxslice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipntr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipntr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m         \u001b[0myslice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipntr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipntr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mido\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 3\n",
    "MODEL_NAME = \"Xception\"\n",
    "\n",
    "print(f\"\\n===== Processing {MODEL_NAME} =====\")\n",
    "\n",
    "X = np.load(f\"{MODEL_NAME}_features.npy\").astype(np.float64)\n",
    "\n",
    "algorithms = get_algorithms(X)\n",
    "results = []\n",
    "\n",
    "for algo_name, algo in algorithms.items():\n",
    "    print(f\"→ Implementing {algo_name} ...\")\n",
    "\n",
    "    try:\n",
    "        # Case 1: callable algorithms (Fuzzy, Spherical)\n",
    "        if callable(algo):\n",
    "            labels = algo(X)\n",
    "\n",
    "        # Case 2: GMM / BayesianGMM\n",
    "        elif hasattr(algo, \"predict\") and not hasattr(algo, \"fit_predict\"):\n",
    "            algo.fit(X)\n",
    "            labels = algo.predict(X)\n",
    "\n",
    "        # Case 3: sklearn clustering\n",
    "        else:\n",
    "            labels = algo.fit_predict(X)\n",
    "\n",
    "        # Skip degenerate clustering\n",
    "        if len(np.unique(labels)) < 2:\n",
    "            raise ValueError(\"Only one cluster formed\")\n",
    "\n",
    "        save_cluster_labels_csv(\n",
    "            MODEL_NAME,\n",
    "            algo_name,\n",
    "            image_names,\n",
    "            original_labels,\n",
    "            labels\n",
    "        )\n",
    "\n",
    "        change = compute_label_change(original_labels_enc, labels)\n",
    "        results.append([MODEL_NAME, algo_name, change])\n",
    "\n",
    "        print(f\"   ✓ Done | Label change: {change:.2f}%\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ✗ Failed: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\"model\", \"clustering\", \"label_percentage_change\"]\n",
    ").to_csv(\n",
    "    \"clustering_results.csv\",\n",
    "    mode=\"a\",\n",
    "    header=not os.path.exists(\"clustering_results.csv\"),\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64X1NZ1IozmT",
    "outputId": "67ecf733-2fde-4502-e110-56d8e7b1d051"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing Xception =====\n",
      "→ Implementing KMeans ...\n",
      "   ✓ Done | Label change: 84.58%\n",
      "→ Implementing MiniBatchKMeans ...\n",
      "   ✓ Done | Label change: 65.63%\n",
      "→ Implementing KMedoids_PAM ...\n",
      "   ✓ Done | Label change: 48.39%\n",
      "→ Implementing BisectingKMeans ...\n",
      "   ✓ Done | Label change: 49.23%\n",
      "→ Implementing SphericalKMeans ...\n",
      "   ✓ Done | Label change: 85.62%\n",
      "→ Implementing FuzzyCMeans ...\n",
      "   ✓ Done | Label change: 81.24%\n",
      "→ Implementing Agglomerative_Single ...\n",
      "   ✓ Done | Label change: 68.92%\n",
      "→ Implementing Agglomerative_Complete ...\n",
      "   ✓ Done | Label change: 65.09%\n",
      "→ Implementing Agglomerative_Average ...\n",
      "   ✓ Done | Label change: 65.19%\n",
      "→ Implementing Agglomerative_Ward ...\n",
      "   ✓ Done | Label change: 46.46%\n",
      "→ Implementing DBSCAN ...\n",
      "   ✓ Done | Label change: 87.26%\n",
      "→ Implementing OPTICS ...\n",
      "   ✓ Done | Label change: 99.85%\n",
      "→ Implementing HDBSCAN ...\n",
      "   ✓ Done | Label change: 70.12%\n",
      "→ Implementing MeanShift ...\n",
      "   ✓ Done | Label change: 70.66%\n",
      "→ Implementing GMM ...\n",
      "   ✓ Done | Label change: 86.29%\n",
      "→ Implementing BayesianGMM ...\n",
      "   ✓ Done | Label change: 86.94%\n",
      "→ Implementing BIRCH ...\n",
      "   ✓ Done | Label change: 71.16%\n",
      "→ Implementing AffinityPropagation ...\n",
      "   ✓ Done | Label change: 99.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/cluster/_affinity_propagation.py:140: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 3\n",
    "MODEL_NAME = \"Xception\"\n",
    "\n",
    "print(f\"\\n===== Processing {MODEL_NAME} =====\")\n",
    "\n",
    "X = np.load(f\"{MODEL_NAME}_features.npy\").astype(np.float64)\n",
    "\n",
    "algorithms = get_algorithms(X)\n",
    "results = []\n",
    "\n",
    "for algo_name, algo in algorithms.items():\n",
    "    print(f\"→ Implementing {algo_name} ...\")\n",
    "\n",
    "    try:\n",
    "        # Case 1: callable algorithms (Fuzzy, Spherical)\n",
    "        if callable(algo):\n",
    "            labels = algo(X)\n",
    "\n",
    "        # Case 2: GMM / BayesianGMM\n",
    "        elif hasattr(algo, \"predict\") and not hasattr(algo, \"fit_predict\"):\n",
    "            algo.fit(X)\n",
    "            labels = algo.predict(X)\n",
    "\n",
    "        # Case 3: sklearn clustering\n",
    "        else:\n",
    "            labels = algo.fit_predict(X)\n",
    "\n",
    "        # Skip degenerate clustering\n",
    "        if len(np.unique(labels)) < 2:\n",
    "            raise ValueError(\"Only one cluster formed\")\n",
    "\n",
    "        save_cluster_labels_csv(\n",
    "            MODEL_NAME,\n",
    "            algo_name,\n",
    "            image_names,\n",
    "            original_labels,\n",
    "            labels\n",
    "        )\n",
    "\n",
    "        change = compute_label_change(original_labels_enc, labels)\n",
    "        results.append([MODEL_NAME, algo_name, change])\n",
    "\n",
    "        print(f\"   ✓ Done | Label change: {change:.2f}%\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ✗ Failed: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\"model\", \"clustering\", \"label_percentage_change\"]\n",
    ").to_csv(\n",
    "    \"clustering_results.csv\",\n",
    "    mode=\"a\",\n",
    "    header=not os.path.exists(\"clustering_results.csv\"),\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "eHwbnXoZfSra",
    "outputId": "24ba9872-b95c-4acf-b17e-1c71d672a6b9"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_26dd1e02-81ca-4e9f-b628-08e7bc1ceeab\", \"clustering_results.csv\", 2920)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.download(\"clustering_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eP89ITn0hXmM",
    "outputId": "c86a5ffa-ad44-44f2-8359-700f5d230fa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: clustering_labels/ (stored 0%)\n",
      "updating: clustering_labels/MobileNetV3_MeanShift.csv (deflated 88%)\n",
      "updating: clustering_labels/VGG19_Agglomerative_Single.csv (deflated 90%)\n",
      "updating: clustering_labels/VGG19_Agglomerative_Ward.csv (deflated 90%)\n",
      "updating: clustering_labels/EfficientNetB0_OPTICS.csv (deflated 86%)\n",
      "updating: clustering_labels/MobileNetV3_HDBSCAN.csv (deflated 90%)\n",
      "updating: clustering_labels/EfficientNetB0_AffinityPropagation.csv (deflated 86%)\n",
      "updating: clustering_labels/EfficientNetB0_MeanShift.csv (deflated 88%)\n",
      "updating: clustering_labels/EfficientNetB0_BisectingKMeans.csv (deflated 88%)\n",
      "updating: clustering_labels/MobileNetV3_Agglomerative_Ward.csv (deflated 88%)\n",
      "updating: clustering_labels/EfficientNetB0_Agglomerative_Average.csv (deflated 88%)\n",
      "updating: clustering_labels/EfficientNetB0_MiniBatchKMeans.csv (deflated 88%)\n",
      "updating: clustering_labels/Xception_Agglomerative_Single.csv (deflated 90%)\n",
      "updating: clustering_labels/ResNet152_Agglomerative_Ward.csv (deflated 90%)\n",
      "updating: clustering_labels/MobileNetV3_KMedoids_PAM.csv (deflated 88%)\n",
      "updating: clustering_labels/MobileNetV3_Agglomerative_Complete.csv (deflated 89%)\n",
      "updating: clustering_labels/ResNet152_SpectralClustering.csv (deflated 90%)\n",
      "updating: clustering_labels/Xception_Agglomerative_Average.csv (deflated 90%)\n",
      "updating: clustering_labels/Xception_MiniBatchKMeans.csv (deflated 89%)\n",
      "updating: clustering_labels/MobileNetV3_BisectingKMeans.csv (deflated 88%)\n",
      "updating: clustering_labels/EfficientNetB0_KMeans.csv (deflated 88%)\n",
      "updating: clustering_labels/EfficientNetB0_DBSCAN.csv (deflated 88%)\n",
      "updating: clustering_labels/Xception_FuzzyCMeans.csv (deflated 88%)\n",
      "updating: clustering_labels/VGG19_Agglomerative_Average.csv (deflated 90%)\n",
      "updating: clustering_labels/MobileNetV3_FuzzyCMeans.csv (deflated 88%)\n",
      "updating: clustering_labels/EfficientNetB0_SpectralClustering.csv (deflated 88%)\n",
      "updating: clustering_labels/EfficientNetB0_HDBSCAN.csv (deflated 88%)\n",
      "updating: clustering_labels/ResNet152_Agglomerative_Complete.csv (deflated 90%)\n",
      "updating: clustering_labels/Xception_KMedoids_PAM.csv (deflated 88%)\n",
      "updating: clustering_labels/Xception_SphericalKMeans.csv (deflated 88%)\n",
      "updating: clustering_labels/Xception_KMeans.csv (deflated 89%)\n",
      "updating: clustering_labels/Xception_Agglomerative_Complete.csv (deflated 90%)\n",
      "updating: clustering_labels/EfficientNetB0_BayesianGMM.csv (deflated 88%)\n",
      "updating: clustering_labels/EfficientNetB0_Agglomerative_Complete.csv (deflated 88%)\n",
      "updating: clustering_labels/MobileNetV3_SphericalKMeans.csv (deflated 88%)\n",
      "updating: clustering_labels/MobileNetV3_Agglomerative_Single.csv (deflated 90%)\n",
      "updating: clustering_labels/Xception_BIRCH.csv (deflated 89%)\n",
      "updating: clustering_labels/Xception_Agglomerative_Ward.csv (deflated 88%)\n",
      "updating: clustering_labels/EfficientNetB0_KMedoids_PAM.csv (deflated 88%)\n",
      "updating: clustering_labels/VGG19_SpectralClustering.csv (deflated 90%)\n",
      "updating: clustering_labels/EfficientNetB0_BIRCH.csv (deflated 88%)\n",
      "updating: clustering_labels/MobileNetV3_KMeans.csv (deflated 88%)\n",
      "updating: clustering_labels/MobileNetV3_MiniBatchKMeans.csv (deflated 88%)\n",
      "updating: clustering_labels/VGG19_Agglomerative_Complete.csv (deflated 90%)\n",
      "updating: clustering_labels/Xception_OPTICS.csv (deflated 87%)\n",
      "updating: clustering_labels/MobileNetV3_AffinityPropagation.csv (deflated 82%)\n",
      "updating: clustering_labels/Xception_GMM.csv (deflated 88%)\n",
      "updating: clustering_labels/Xception_AffinityPropagation.csv (deflated 85%)\n",
      "updating: clustering_labels/MobileNetV3_BayesianGMM.csv (deflated 90%)\n",
      "updating: clustering_labels/EfficientNetB0_Agglomerative_Single.csv (deflated 90%)\n",
      "updating: clustering_labels/EfficientNetB0_Agglomerative_Ward.csv (deflated 88%)\n",
      "updating: clustering_labels/Xception_HDBSCAN.csv (deflated 89%)\n",
      "updating: clustering_labels/ResNet152_Agglomerative_Single.csv (deflated 90%)\n",
      "updating: clustering_labels/MobileNetV3_SpectralClustering.csv (deflated 88%)\n",
      "updating: clustering_labels/ResNet152_Agglomerative_Average.csv (deflated 90%)\n",
      "updating: clustering_labels/EfficientNetB0_SphericalKMeans.csv (deflated 88%)\n",
      "updating: clustering_labels/MobileNetV3_Agglomerative_Average.csv (deflated 89%)\n",
      "updating: clustering_labels/Xception_BayesianGMM.csv (deflated 88%)\n",
      "updating: clustering_labels/Xception_BisectingKMeans.csv (deflated 89%)\n",
      "updating: clustering_labels/Xception_MeanShift.csv (deflated 88%)\n",
      "updating: clustering_labels/EfficientNetB0_GMM.csv (deflated 88%)\n",
      "updating: clustering_labels/MobileNetV3_OPTICS.csv (deflated 85%)\n",
      "updating: clustering_labels/EfficientNetB0_FuzzyCMeans.csv (deflated 88%)\n",
      "updating: clustering_labels/Xception_DBSCAN.csv (deflated 87%)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_fa07839e-3506-4da8-8be3-4c8e09aa565f\", \"clustering_labels.zip\", 968792)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!zip -r clustering_labels.zip clustering_labels\n",
    "files.download(\"clustering_labels.zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kDg3_6_rwCDE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Change (EfficientNetB0 + KMeans) Silhouette Score: 0.8246\n",
      "Maximum Change (Xception + Birch) Silhouette Score: 0.7279\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# ============================\n",
    "# LOAD FEATURES\n",
    "# ============================\n",
    "\n",
    "X_eff = np.load(\"EfficientNetB0_features.npy\")\n",
    "X_xcep = np.load(\"Xception_features.npy\")\n",
    "\n",
    "# ============================\n",
    "# LOAD CLUSTER LABEL FILES\n",
    "# ============================\n",
    "\n",
    "eff_kmeans_df = pd.read_csv(\"clustering_labels/EfficientNetB0_KMeans.csv\")\n",
    "xcep_birch_df = pd.read_csv(\"clustering_labels/Xception_BIRCH.csv\")\n",
    "\n",
    "labels_eff = eff_kmeans_df[\"cluster_label\"].values\n",
    "labels_xcep = xcep_birch_df[\"cluster_label\"].values\n",
    "\n",
    "# ============================\n",
    "# REMOVE NOISE IF PRESENT (-1)\n",
    "# ============================\n",
    "\n",
    "def compute_silhouette(X, labels, name):\n",
    "    unique_labels = np.unique(labels)\n",
    "\n",
    "    if len(unique_labels) < 2:\n",
    "        print(f\"{name}: Cannot compute silhouette (only one cluster)\")\n",
    "        return None\n",
    "\n",
    "    # Remove noise label -1 if exists\n",
    "    mask = labels != -1\n",
    "    X_clean = X[mask]\n",
    "    labels_clean = labels[mask]\n",
    "\n",
    "    if len(np.unique(labels_clean)) < 2:\n",
    "        print(f\"{name}: Not enough valid clusters after removing noise\")\n",
    "        return None\n",
    "\n",
    "    score = silhouette_score(X_clean, labels_clean)\n",
    "    print(f\"{name} Silhouette Score: {score:.4f}\")\n",
    "    return score\n",
    "\n",
    "\n",
    "# ============================\n",
    "# COMPUTE SCORES\n",
    "# ============================\n",
    "\n",
    "score_min = compute_silhouette(\n",
    "    X_eff,\n",
    "    labels_eff,\n",
    "    \"Minimum Change (EfficientNetB0 + KMeans)\"\n",
    ")\n",
    "\n",
    "score_max = compute_silhouette(\n",
    "    X_xcep,\n",
    "    labels_xcep,\n",
    "    \"Maximum Change (Xception + Birch)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
