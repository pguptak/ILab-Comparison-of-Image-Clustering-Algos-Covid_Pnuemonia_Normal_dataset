{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "610fb5d7-f8c3-4120-b9ba-0d7f3c772d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atish\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3154ce10-1ba4-42f0-89e4-9d60fc3772a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZIP_PATH = \"covid+pneumonia+normal.zip\"\n",
    "\n",
    "WORKING_DIR = \"CPN_working\"\n",
    "DATA_DIR = os.path.join(WORKING_DIR, \"CPN\")\n",
    "MIXED_DIR = os.path.join(WORKING_DIR, \"mixed_images\")\n",
    "\n",
    "os.makedirs(WORKING_DIR, exist_ok=True)\n",
    "os.makedirs(MIXED_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "061afbd3-6e22-45de-abb3-0cf8c88ed9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset unzipped completely\n"
     ]
    }
   ],
   "source": [
    "with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
    "    zip_ref.extractall(WORKING_DIR)\n",
    "print(\"‚úÖ Dataset unzipped completely\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fb4df61-c8cd-4dac-bca1-293d27058f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Dataset root detected: CPN_working\n",
      "‚û°Ô∏è Processing class: COVID\n",
      "‚û°Ô∏è Processing class: NORMAL\n",
      "‚û°Ô∏è Processing class: PNEUMONIA\n",
      "‚úÖ Mixed images created: 5228\n",
      "‚úÖ labels.csv saved successfully\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "image_records = []\n",
    "image_counter = 0\n",
    "\n",
    "# Dataset root (class folders inside this)\n",
    "dataset_root = WORKING_DIR\n",
    "print(\"üìÇ Dataset root detected:\", dataset_root)\n",
    "\n",
    "# Loop through each class folder\n",
    "for class_name in sorted(os.listdir(dataset_root)):\n",
    "    class_path = os.path.join(dataset_root, class_name)\n",
    "\n",
    "    # Skip non-directories and mixed_images folder\n",
    "    if not os.path.isdir(class_path) or class_name == \"mixed_images\":\n",
    "        continue\n",
    "\n",
    "    print(f\"‚û°Ô∏è Processing class: {class_name}\")\n",
    "\n",
    "    for image_name in sorted(os.listdir(class_path)):\n",
    "        if image_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "\n",
    "            image_counter += 1\n",
    "            new_image_name = f\"img_{image_counter:06d}.png\"\n",
    "\n",
    "            src_path = os.path.join(class_path, image_name)\n",
    "            dst_path = os.path.join(MIXED_DIR, new_image_name)\n",
    "\n",
    "            shutil.copy(src_path, dst_path)\n",
    "\n",
    "            # Store mapping\n",
    "            image_records.append({\n",
    "                \"image_name\": new_image_name,\n",
    "                \"label\": class_name\n",
    "            })\n",
    "\n",
    "print(f\"‚úÖ Mixed images created: {image_counter}\")\n",
    "\n",
    "# Save labels.csv\n",
    "labels_df = pd.DataFrame(image_records)\n",
    "LABELS_CSV = os.path.join(WORKING_DIR, \"labels.csv\")\n",
    "labels_df.to_csv(LABELS_CSV, index=False)\n",
    "\n",
    "print(\"‚úÖ labels.csv saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e144aa0-e3b4-4099-a169-42b125da1b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5228 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "data_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=labels_df,\n",
    "    directory=MIXED_DIR,\n",
    "    x_col=\"image_name\",\n",
    "    y_col=\"label\",\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2058d8d-1fe4-4c7f-80bf-597266738fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet152():\n",
    "    base = tf.keras.applications.ResNet152(\n",
    "        include_top=False, weights=None, input_shape=(*IMG_SIZE,3)\n",
    "    )\n",
    "    x = layers.GlobalAveragePooling2D()(base.output)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    out = layers.Dense(3, activation='softmax')(x)\n",
    "    return Model(base.input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce8ea216-5f98-4298-8cf5-9dd916ad65ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vgg19():\n",
    "    base = tf.keras.applications.VGG19(\n",
    "        include_top=False, weights=None, input_shape=(*IMG_SIZE,3)\n",
    "    )\n",
    "    x = layers.Flatten()(base.output)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    out = layers.Dense(3, activation='softmax')(x)\n",
    "    return Model(base.input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a785acc-7ba9-491b-bc83-ec318ea46be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_xception():\n",
    "    base = tf.keras.applications.Xception(\n",
    "        include_top=False, weights=None, input_shape=(*IMG_SIZE,3)\n",
    "    )\n",
    "    x = layers.GlobalAveragePooling2D()(base.output)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    out = layers.Dense(3, activation='softmax')(x)\n",
    "    return Model(base.input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b63c8f09-6689-428b-80bf-15415ae9b661",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_mobilenet_v3():\n",
    "    base = tf.keras.applications.MobileNetV3Large(\n",
    "        include_top=False, weights=None, input_shape=(*IMG_SIZE,3)\n",
    "    )\n",
    "    x = layers.GlobalAveragePooling2D()(base.output)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    out = layers.Dense(3, activation='softmax')(x)\n",
    "    return Model(base.input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb01ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def build_efficientnetb0():\n",
    "    base = tf.keras.applications.EfficientNetB0(\n",
    "        include_top=False,\n",
    "        weights=None,          # keep None to match ResNet152 setup\n",
    "        input_shape=(*IMG_SIZE, 3)\n",
    "    )\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(base.output)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    out = layers.Dense(3, activation='softmax')(x)\n",
    "\n",
    "    return Model(inputs=base.input, outputs=out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419361f1-a476-4160-b113-1b9852de9ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Encode labels\n",
    "labels = labels_df[\"label\"].values\n",
    "classes = np.unique(labels)\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=classes,\n",
    "    y=labels\n",
    ")\n",
    "\n",
    "class_weight_dict = dict(zip(range(len(classes)), class_weights))\n",
    "\n",
    "print(\"Class Weights:\", class_weight_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c62fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_DIR = \"/content/saved_features\"\n",
    "LABEL_DIR = \"/content/saved_labels\"\n",
    "\n",
    "os.makedirs(FEATURE_DIR, exist_ok=True)\n",
    "os.makedirs(LABEL_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ae964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "true_labels = le.fit_transform(labels_df[\"label\"])\n",
    "\n",
    "np.save(f\"{LABEL_DIR}/true_labels.npy\", true_labels)\n",
    "print(\"‚úÖ True labels saved:\", true_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee14d0d0-6421-413f-ac91-89dbd727c4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "data_gen.shuffle = False  # VERY IMPORTANT\n",
    "\n",
    "results = []\n",
    "\n",
    "def train_and_extract(model, name):\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        data_gen,\n",
    "        class_weight=class_weight_dict,\n",
    "        epochs=10,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "   \n",
    "\n",
    "    feature_model = Model(\n",
    "        inputs=model.input,\n",
    "        outputs=model.layers[-2].output\n",
    "    )\n",
    "\n",
    "    features = feature_model.predict(data_gen)\n",
    "\n",
    "    np.save(f\"{FEATURE_DIR}/{name}_features.npy\", features)\n",
    "    model.save(f\"/content/{name}.h5\")\n",
    "\n",
    "    print(f\"‚úÖ {name} features saved:\", features.shape)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def cluster_with_scaling_pca(features, model_name):\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "    pca = PCA(n_components=0.95, random_state=42)\n",
    "    features_pca = pca.fit_transform(features_scaled)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(features_pca)\n",
    "\n",
    "    label_change_percent = np.mean(cluster_labels != true_labels) * 100\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Label Change (%)\": round(label_change_percent, 2),\n",
    "        \"PCA Components\": features_pca.shape[1]\n",
    "    })\n",
    "\n",
    "np.save(f\"{LABEL_DIR}/true_labels.npy\", true_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9483b30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = build_resnet152()\n",
    "resnet_features = train_and_extract(resnet_model, \"ResNet152\")\n",
    "cluster_with_scaling_pca(resnet_features, \"ResNet152\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc9edd4-810f-4d9e-b46e-8eaae8fbde50",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = build_vgg19()\n",
    "vgg_features = train_and_extract(vgg_model, \"VGG19\")\n",
    "cluster_with_scaling_pca(vgg_features, \"VGG19\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056c2d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "xception_model = build_xception()\n",
    "xception_features = train_and_extract(xception_model, \"Xception\")\n",
    "cluster_with_scaling_pca(xception_features, \"Xception\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1294893",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_model = build_mobilenet_v3()\n",
    "mobilenet_features = train_and_extract(mobilenet_model, \"MobileNetV3\")\n",
    "cluster_with_scaling_pca(mobilenet_features, \"MobileNetV3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede21602",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_model = build_efficientnetb0()\n",
    "efficientnet_features = train_and_extract(\n",
    "    efficientnet_model,\n",
    "    \"EfficientNetB0\"\n",
    ")\n",
    "\n",
    "cluster_with_scaling_pca(efficientnet_features, \"EfficientNetB0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d45ee39-50cc-48fc-a96a-87474e44a3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n",
    "results_df.to_csv(\"clustering_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2183af39-8d6f-401f-a4ee-6ef179c8cef4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
