{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "846d490b-3e17-4fdf-ba30-306f91676408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0, Xception\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2985bdd2-1d00-4394-8002-ac40e7582231",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "SEED = 42\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbf7d32d-f808-461d-8e98-cc7d2fed05f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv(\"original_labels.csv\")\n",
    "eff_kmeans_df = pd.read_csv(\"EfficientNetB0_KMeans.csv\")\n",
    "\n",
    "# If you have Xception-Birch file:\n",
    "xcep_birch_df = pd.read_csv(\"Xception_Birch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2aafdad5-86b6-4c49-b9ab-c897de0187d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, label_column):\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    df[\"label_encoded\"] = le.fit_transform(df[label_column])\n",
    "\n",
    "    num_classes = df[\"label_encoded\"].nunique()\n",
    "\n",
    "    X = df[\"image_name\"].values\n",
    "    y = to_categorical(df[\"label_encoded\"], num_classes)\n",
    "\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y,\n",
    "        test_size=0.3,\n",
    "        random_state=SEED,\n",
    "        stratify=df[\"label_encoded\"]\n",
    "    )\n",
    "\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp,\n",
    "        test_size=0.5,\n",
    "        random_state=SEED\n",
    "    )\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e6897af-bec7-4d5c-8fd0-4a5ce53c4855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "MIXED_FOLDER = \"CPN_working\\mixed_images\"   \n",
    "\n",
    "def load_image(image_name):\n",
    "    full_path = os.path.join(MIXED_FOLDER, image_name)\n",
    "\n",
    "    img = tf.keras.preprocessing.image.load_img(\n",
    "        full_path,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE)\n",
    "    )\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "\n",
    "def create_dataset(X, y):\n",
    "    images = np.array([load_image(name) for name in X])\n",
    "    return images, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b066966e-ba5b-4a9a-8a74-6540f985c291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_efficientnet(num_classes):\n",
    "\n",
    "    base = EfficientNetB0(\n",
    "        weights=None,            # NO pretrained\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "    )\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base.output)\n",
    "    output = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=base.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4309ea38-30c5-4a30-8920-3c799f83d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_xception(num_classes):\n",
    "\n",
    "    base = Xception(\n",
    "        weights=None,           # NO pretrained\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "    )\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base.output)\n",
    "    output = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=base.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b188eb20-2d16-46a1-bdd0-301dfdd8ea9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 1s/step - accuracy: 0.7641 - loss: 0.6330 - val_accuracy: 0.3355 - val_loss: 3.4596\n",
      "Epoch 2/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - accuracy: 0.9016 - loss: 0.2739 - val_accuracy: 0.3355 - val_loss: 5.0231\n",
      "Epoch 3/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 1s/step - accuracy: 0.9385 - loss: 0.1789 - val_accuracy: 0.3355 - val_loss: 5.6955\n",
      "Epoch 4/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - accuracy: 0.9519 - loss: 0.1495 - val_accuracy: 0.3355 - val_loss: 3.4960\n",
      "Epoch 5/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - accuracy: 0.9779 - loss: 0.0684 - val_accuracy: 0.5510 - val_loss: 4.2294\n",
      "Epoch 6/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - accuracy: 0.9746 - loss: 0.0750 - val_accuracy: 0.7793 - val_loss: 0.9717\n",
      "Epoch 7/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 1s/step - accuracy: 0.9735 - loss: 0.0705 - val_accuracy: 0.7143 - val_loss: 2.2695\n",
      "Epoch 8/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - accuracy: 0.9787 - loss: 0.0687 - val_accuracy: 0.9566 - val_loss: 0.1765\n",
      "Epoch 9/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 1s/step - accuracy: 0.9877 - loss: 0.0382 - val_accuracy: 0.9209 - val_loss: 0.2573\n",
      "Epoch 10/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - accuracy: 0.9921 - loss: 0.0242 - val_accuracy: 0.9528 - val_loss: 0.1268\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 206ms/step - accuracy: 0.9452 - loss: 0.1569\n",
      "EfficientNet trained on ORIGINAL labels Accuracy: 0.9452229142189026\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, num_classes = prepare_data(original_df)\n",
    "\n",
    "X_train_img, y_train = create_dataset(X_train, y_train)\n",
    "X_val_img, y_val = create_dataset(X_val, y_val)\n",
    "X_test_img, y_test = create_dataset(X_test, y_test)\n",
    "\n",
    "model_eff_original = build_efficientnet(num_classes)\n",
    "\n",
    "model_eff_original.fit(\n",
    "    X_train_img, y_train,\n",
    "    validation_data=(X_val_img, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "loss1, acc1 = model_eff_original.evaluate(X_test_img, y_test)\n",
    "print(\"EfficientNet trained on ORIGINAL labels Accuracy:\", acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c886d688-7966-4f2a-9dc5-c1d325f211e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 1s/step - accuracy: 0.7948 - loss: 0.5500 - val_accuracy: 0.2883 - val_loss: 4.1297\n",
      "Epoch 2/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 1s/step - accuracy: 0.8819 - loss: 0.3198 - val_accuracy: 0.2883 - val_loss: 7.7864\n",
      "Epoch 3/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 1s/step - accuracy: 0.9016 - loss: 0.2672 - val_accuracy: 0.2883 - val_loss: 5.7395\n",
      "Epoch 4/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - accuracy: 0.9065 - loss: 0.2496 - val_accuracy: 0.2883 - val_loss: 6.3877\n",
      "Epoch 5/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - accuracy: 0.9248 - loss: 0.1991 - val_accuracy: 0.2883 - val_loss: 5.0916\n",
      "Epoch 6/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 1s/step - accuracy: 0.9333 - loss: 0.1796 - val_accuracy: 0.3163 - val_loss: 3.4720\n",
      "Epoch 7/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 1s/step - accuracy: 0.9437 - loss: 0.1539 - val_accuracy: 0.8610 - val_loss: 0.4170\n",
      "Epoch 8/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 1s/step - accuracy: 0.9549 - loss: 0.1265 - val_accuracy: 0.8699 - val_loss: 0.4068\n",
      "Epoch 9/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 1s/step - accuracy: 0.9642 - loss: 0.1092 - val_accuracy: 0.7691 - val_loss: 0.9645\n",
      "Epoch 10/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 1s/step - accuracy: 0.9743 - loss: 0.0778 - val_accuracy: 0.8469 - val_loss: 0.6487\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 211ms/step - accuracy: 0.8624 - loss: 0.6374\n",
      "\n",
      "EfficientNet trained on KMeans labels Accuracy: 0.862420380115509\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, num_classes = prepare_data(\n",
    "    eff_kmeans_df,\n",
    "    label_column=\"cluster_label\"   # <-- adjust if needed\n",
    ")\n",
    "\n",
    "X_train_img, y_train = create_dataset(X_train, y_train)\n",
    "X_val_img, y_val = create_dataset(X_val, y_val)\n",
    "X_test_img, y_test = create_dataset(X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_eff_cluster = build_efficientnet(num_classes)\n",
    "\n",
    "model_eff_cluster.fit(\n",
    "    X_train_img, y_train,\n",
    "    validation_data=(X_val_img, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "loss2, acc2 = model_eff_cluster.evaluate(X_test_img, y_test)\n",
    "\n",
    "print(\"\\nEfficientNet trained on KMeans labels Accuracy:\", acc2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3161b3ac-2ac2-4153-9c18-c2c9fd0bfb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 3s/step - accuracy: 0.8792 - loss: 0.3378 - val_accuracy: 0.3227 - val_loss: 1.1084\n",
      "Epoch 2/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 3s/step - accuracy: 0.9374 - loss: 0.1786 - val_accuracy: 0.3227 - val_loss: 1.2263\n",
      "Epoch 3/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 3s/step - accuracy: 0.9549 - loss: 0.1328 - val_accuracy: 0.3227 - val_loss: 1.5976\n",
      "Epoch 4/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 3s/step - accuracy: 0.9634 - loss: 0.1093 - val_accuracy: 0.4668 - val_loss: 1.9971\n",
      "Epoch 5/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 3s/step - accuracy: 0.9724 - loss: 0.0833 - val_accuracy: 0.6301 - val_loss: 1.3915\n",
      "Epoch 6/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 3s/step - accuracy: 0.9656 - loss: 0.0952 - val_accuracy: 0.5727 - val_loss: 1.8586\n",
      "Epoch 7/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 3s/step - accuracy: 0.9770 - loss: 0.0673 - val_accuracy: 0.8929 - val_loss: 0.3868\n",
      "Epoch 8/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 3s/step - accuracy: 0.9850 - loss: 0.0420 - val_accuracy: 0.6059 - val_loss: 2.5019\n",
      "Epoch 9/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 3s/step - accuracy: 0.9828 - loss: 0.0511 - val_accuracy: 0.9247 - val_loss: 0.2281\n",
      "Epoch 10/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 3s/step - accuracy: 0.9743 - loss: 0.0653 - val_accuracy: 0.9630 - val_loss: 0.1565\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 536ms/step - accuracy: 0.9580 - loss: 0.1281\n",
      "\n",
      "Xception trained on ORIGINAL labels Accuracy: 0.9579617977142334\n"
     ]
    }
   ],
   "source": [
    "# Prepare data (original labels)\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, num_classes = prepare_data(\n",
    "    original_df,\n",
    "    label_column=\"label\"   # original label column\n",
    ")\n",
    "\n",
    "X_train_img, y_train = create_dataset(X_train, y_train)\n",
    "X_val_img, y_val = create_dataset(X_val, y_val)\n",
    "X_test_img, y_test = create_dataset(X_test, y_test)\n",
    "\n",
    "# Build model\n",
    "model_x_original = build_xception(num_classes)\n",
    "\n",
    "# Train\n",
    "model_x_original.fit(\n",
    "    X_train_img, y_train,\n",
    "    validation_data=(X_val_img, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss3, acc3 = model_x_original.evaluate(X_test_img, y_test)\n",
    "\n",
    "print(\"\\nXception trained on ORIGINAL labels Accuracy:\", acc3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36a175b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 3s/step - accuracy: 0.9552 - loss: 0.1453 - val_accuracy: 0.9439 - val_loss: 0.6226\n",
      "Epoch 2/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 3s/step - accuracy: 0.9724 - loss: 0.0883 - val_accuracy: 0.9439 - val_loss: 0.2381\n",
      "Epoch 3/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 3s/step - accuracy: 0.9825 - loss: 0.0513 - val_accuracy: 0.9439 - val_loss: 0.2633\n",
      "Epoch 4/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 3s/step - accuracy: 0.9820 - loss: 0.0536 - val_accuracy: 0.9439 - val_loss: 0.4310\n",
      "Epoch 5/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 3s/step - accuracy: 0.9803 - loss: 0.0591 - val_accuracy: 0.9541 - val_loss: 0.2266\n",
      "Epoch 6/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 3s/step - accuracy: 0.9855 - loss: 0.0456 - val_accuracy: 0.9758 - val_loss: 0.0556\n",
      "Epoch 7/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 3s/step - accuracy: 0.9869 - loss: 0.0345 - val_accuracy: 0.9719 - val_loss: 0.0794\n",
      "Epoch 8/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 3s/step - accuracy: 0.9872 - loss: 0.0371 - val_accuracy: 0.9707 - val_loss: 0.0838\n",
      "Epoch 9/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 3s/step - accuracy: 0.9896 - loss: 0.0311 - val_accuracy: 0.9554 - val_loss: 0.1372\n",
      "Epoch 10/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 3s/step - accuracy: 0.9852 - loss: 0.0396 - val_accuracy: 0.9707 - val_loss: 0.0624\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 531ms/step - accuracy: 0.9745 - loss: 0.0992\n",
      "\n",
      "Xception trained on Birch labels Accuracy: 0.9745222926139832\n"
     ]
    }
   ],
   "source": [
    "# Prepare data (Birch cluster labels)\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, num_classes = prepare_data(\n",
    "    xcep_birch_df,\n",
    "    label_column=\"cluster_label\"   # <-- change if different\n",
    ")\n",
    "\n",
    "X_train_img, y_train = create_dataset(X_train, y_train)\n",
    "X_val_img, y_val = create_dataset(X_val, y_val)\n",
    "X_test_img, y_test = create_dataset(X_test, y_test)\n",
    "\n",
    "# Build model\n",
    "model_x_cluster = build_xception(num_classes)\n",
    "\n",
    "# Train\n",
    "model_x_cluster.fit(\n",
    "    X_train_img, y_train,\n",
    "    validation_data=(X_val_img, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss4, acc4 = model_x_cluster.evaluate(X_test_img, y_test)\n",
    "\n",
    "print(\"\\nXception trained on Birch labels Accuracy:\", acc4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "938c1dd8-44ad-4d7d-8784-3aaf1f6beafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== FINAL RESULTS ==========\n",
      "EfficientNet Original Accuracy: 0.9452229142189026\n",
      "EfficientNet Cluster Accuracy : 0.862420380115509\n",
      "Xception Original Accuracy    : 0.9579617977142334\n",
      "Xception Cluster Accuracy     : 0.9745222926139832\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========================\n",
    "# FINAL COMPARISON\n",
    "# =========================\n",
    "\n",
    "print(\"\\n========== FINAL RESULTS ==========\")\n",
    "print(\"EfficientNet Original Accuracy:\", acc1)\n",
    "print(\"EfficientNet Cluster Accuracy :\", acc2)\n",
    "print(\"Xception Original Accuracy    :\", acc3)\n",
    "print(\"Xception Cluster Accuracy     :\", acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc432ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
